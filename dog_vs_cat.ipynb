{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-1: Build CNN\n",
    "# Initialize CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1st convolution layer\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=(3, 3), input_shape=(64, 64, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1st pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2nd convolution layer\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2nd pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 3rd convolution layer\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 3rd pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten layer\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dense layer\n",
    "classifier.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile classifier\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-2: image preprocessing\n",
    "# import libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagene = ImageDataGenerator(rescale=1./255, \n",
    "                                    shear_range=0.2, \n",
    "                                    rotation_range=0.2, \n",
    "                                   horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagene = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 955 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagene.flow_from_directory(directory=\"/resources/data/dataset/training_set\", \n",
    "                                                  target_size=(64, 64), \n",
    "                                                  class_mode='binary', \n",
    "                                                  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagene.flow_from_directory(directory=\"/resources/data/dataset/test_set\", \n",
    "                                            target_size=(64, 64), \n",
    "                                            class_mode='binary', \n",
    "                                            batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "955/955 [==============================] - 228s 239ms/step - loss: 0.2422 - acc: 0.9160 - val_loss: 1.6187 - val_acc: 0.7379\n",
      "Epoch 2/20\n",
      "955/955 [==============================] - 226s 237ms/step - loss: 0.0189 - acc: 0.9941 - val_loss: 2.7908 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "955/955 [==============================] - 227s 237ms/step - loss: 1.6385e-04 - acc: 1.0000 - val_loss: 2.9645 - val_acc: 0.7150\n",
      "Epoch 4/20\n",
      "955/955 [==============================] - 229s 239ms/step - loss: 5.2241e-05 - acc: 1.0000 - val_loss: 3.0147 - val_acc: 0.7214\n",
      "Epoch 5/20\n",
      "955/955 [==============================] - 224s 235ms/step - loss: 2.2176e-05 - acc: 1.0000 - val_loss: 3.1116 - val_acc: 0.7206\n",
      "Epoch 6/20\n",
      "955/955 [==============================] - 223s 234ms/step - loss: 1.0716e-05 - acc: 1.0000 - val_loss: 3.1144 - val_acc: 0.7279\n",
      "Epoch 7/20\n",
      "955/955 [==============================] - 222s 232ms/step - loss: 5.5540e-06 - acc: 1.0000 - val_loss: 3.1790 - val_acc: 0.7333\n",
      "Epoch 8/20\n",
      "955/955 [==============================] - 227s 237ms/step - loss: 2.9367e-06 - acc: 1.0000 - val_loss: 3.1913 - val_acc: 0.7322\n",
      "Epoch 9/20\n",
      "955/955 [==============================] - 225s 236ms/step - loss: 1.6776e-06 - acc: 1.0000 - val_loss: 3.2524 - val_acc: 0.7322\n",
      "Epoch 10/20\n",
      "955/955 [==============================] - 225s 235ms/step - loss: 9.7585e-07 - acc: 1.0000 - val_loss: 3.2682 - val_acc: 0.7324\n",
      "Epoch 11/20\n",
      "955/955 [==============================] - 222s 233ms/step - loss: 5.8846e-07 - acc: 1.0000 - val_loss: 3.3035 - val_acc: 0.7268\n",
      "Epoch 12/20\n",
      "955/955 [==============================] - 223s 233ms/step - loss: 3.7850e-07 - acc: 1.0000 - val_loss: 3.3175 - val_acc: 0.7263\n",
      "Epoch 13/20\n",
      "955/955 [==============================] - 226s 237ms/step - loss: 2.5216e-07 - acc: 1.0000 - val_loss: 3.3316 - val_acc: 0.7272\n",
      "Epoch 14/20\n",
      "955/955 [==============================] - 226s 237ms/step - loss: 1.4520e-07 - acc: 1.0000 - val_loss: 3.3757 - val_acc: 0.7216\n",
      "Epoch 16/20\n",
      "955/955 [==============================] - 221s 231ms/step - loss: 1.1254e-07 - acc: 1.0000 - val_loss: 3.3965 - val_acc: 0.7270\n",
      "Epoch 18/20\n",
      "955/955 [==============================] - 224s 234ms/step - loss: 1.0401e-07 - acc: 1.0000 - val_loss: 3.3986 - val_acc: 0.7374\n",
      "Epoch 20/20\n",
      "827/955 [========================>.....] - ETA: 26s - loss: 1.0273e-07 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "classifier.fit_generator(generator=training_set, \n",
    "                         steps_per_epoch=955, \n",
    "                         epochs=20, \n",
    "                         validation_data=test_set, \n",
    "                         validation_steps=183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-3: new prediction\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test image\n",
    "test_img = image.load_img(path=\"/resources/data/dataset/prediction/cat_or_dog_1.jpg\", target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reszie image\n",
    "test_img = image.img_to_array(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch-dimension in image shape\n",
    "test_img = np.expand_dims(test_img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to know which class is represented by 0, 1\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
